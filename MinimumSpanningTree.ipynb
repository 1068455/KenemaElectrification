{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "import time\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "from scipy.spatial import Delaunay\n",
    "from shapely.geometry import LineString\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-investing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Enter the right datafile\n",
    "buildings = 'SLE_KenemaRadius_OSMBuildings.geojson'\n",
    "\n",
    "print('Loading data...')\n",
    "# Prepare building data - read as geodataframe\n",
    "gdf = gp.read_file(buildings)\n",
    "# Get the number of rows (points) in the GeoDataFrame\n",
    "no_points = gdf.shape[0]\n",
    "gdf.head()\n",
    "print(no_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroid points of building polygons\n",
    "gdf['centroid'] = gdf['geometry'].centroid\n",
    "# Break out lat and long into separate columns of GeoDataFrame\n",
    "gdf['lon'] = gdf.centroid.x\n",
    "gdf['lat'] = gdf.centroid.y\n",
    "# Get lat and long columns from the GeoDataFrame and convert into a numpy array\n",
    "coords = gdf.drop(['name', 'type', 'code', 'fclass', 'osm_id', 'geometry', 'centroid'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot home locations\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('Home locations')\n",
    "plt.scatter(x=coords[:, 0], y=coords[:, 1],color='b', s=3, alpha=0.8)\n",
    "plt.xlabel('Longitude ($^\\circ$)')\n",
    "plt.ylabel('Latitude ($^\\circ$)')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([min(coords[:, 0]) - 0.001, max(coords[:, 0]) + 0.001])\n",
    "axes.set_ylim([min(coords[:, 1]) - 0.001, max(coords[:, 1]) + 0.001])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-eleven",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cluster the data\n",
    "\n",
    "clust = OPTICS(min_samples= 10, xi=.7, min_cluster_size= 10)\n",
    "\n",
    "# Run the fit\n",
    "clust.fit(coords)\n",
    "labelsOp = clust.labels_[clust.ordering_]\n",
    "\n",
    "# See how many houses in each cluster. cluster -1 = outlier\n",
    "(unique, counts) = np.unique(labelsOp, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "#plot results\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "labels = labelsOp\n",
    "for klass in zip(range(0, 297)):\n",
    "    plt.scatter(x=coords[labels == klass, 0], y=coords[labels == klass, 1],color=np.random.rand(3), s=5, alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-release",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use DBSCAN method\n",
    "\n",
    "labelsF = cluster_optics_dbscan(reachability=clust.reachability_,\n",
    "                                   core_distances=clust.core_distances_,\n",
    "                                   ordering=clust.ordering_, eps=0.002)\n",
    "\n",
    "# See how many houses in each cluster. -1 = outlier\n",
    "(unique, counts) = np.unique(labelsF, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "labels = labelsF\n",
    "for klass in zip(range(0, 297)):\n",
    "    plt.scatter(x=coords[labels == klass, 0], y=coords[labels == klass, 1],color=np.random.rand(3), s=5, alpha=0.8)\n",
    "\n",
    "#plot outliers\n",
    "# plt.scatter(x=coords[clust.labels_ == -1, 0], y=coords[clust.labels_ == -1, 1],color='k', s=1, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine formula for kilometer distance between two lat/long points\n",
    "def haversine_dist_from_coords(lat1, lon1, lat2, lon2):\n",
    "    # The math module contains a function named radians which converts from degrees to radians.\n",
    "    lon1 = radians(lon1)\n",
    "    lon2 = radians(lon2)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    # Radius of earth in kilometers. Use 3956 for miles\n",
    "    r = 6371\n",
    "    # calculate and return the result\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-database",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For each cluster, perform delaunay triangulation and save the result as a shp file to be able to visualise\n",
    "#final cabling layout in QGIS\n",
    "\n",
    "total_distance_under100 = 0\n",
    "total_distance_100_300 = 0\n",
    "total_distance_300_500 = 0\n",
    "total_distance_1000 = 0\n",
    "clusters_under_100 = 0\n",
    "clusters_100_300 = 0\n",
    "clusters_300_500 = 0\n",
    "clusters_1000 = 0\n",
    "\n",
    "for klass in range(0,298):\n",
    "    newcoords = coords[labels ==klass]\n",
    "    \n",
    "    no_points = len(newcoords)\n",
    "    print(no_points)\n",
    "    \n",
    "    print('Calculating Delaunay triangulation and distance between Delaunay neighbours...')\n",
    "    # Get Delauney triangulation of coordinates\n",
    "    tri = Delaunay(newcoords)\n",
    "    indices = tri.vertex_neighbor_vertices[0]\n",
    "    indptr = tri.vertex_neighbor_vertices[1]\n",
    "    \n",
    "    # Instantiate dictionary to hold neighbors of each point & data-frame to hold distances between neighbours\n",
    "    neighbors = {}\n",
    "    locations = {}\n",
    "    distances = pd.DataFrame(columns=[\"source\", \"dest\", \"distance\"])\n",
    "    \n",
    "    # Get dictionary of neighbors of all points and a dictionary of locations of all points\n",
    "    for k in range(0, no_points):\n",
    "        neighbors[k] = indptr[indices[k]:indices[k+1]]\n",
    "        locations[k] = newcoords[k][0], newcoords[k][1]\n",
    "    \n",
    "    # Get distances between all Delaunay neighbors\n",
    "    for key, values in neighbors.items():\n",
    "        for value in values:\n",
    "            coord_1 = newcoords[key]\n",
    "            coord_2 = newcoords[value]\n",
    "            dist = haversine_dist_from_coords(coord_1[1], coord_1[0], coord_2[1], coord_2[0])\n",
    "            distances = distances.append({\"source\": key, \"dest\": value, \"distance\": dist}, ignore_index=True)\n",
    "            \n",
    "    # Plot Delaunay triangulation\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.title('Delaunay Triangulation of Homes')\n",
    "    plt.triplot(newcoords[:, 0], newcoords[:, 1], tri.simplices)\n",
    "    plt.xlabel('Longitude ($^\\circ$)')\n",
    "    plt.ylabel('Latitude ($^\\circ$)')\n",
    "    plt.plot(newcoords[:, 0], newcoords[:, 1], 'o')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([min(newcoords[:, 0]) - 0.001, max(newcoords[:, 0]) + 0.001])\n",
    "    axes.set_ylim([min(newcoords[:, 1]) - 0.001, max(newcoords[:, 1]) + 0.001])\n",
    "    \n",
    "    print('Creating a graph from this information (edge weight = distance)...')\n",
    "    G = nx.Graph()\n",
    "    for index, row in distances.iterrows():\n",
    "        G.add_edge(row['source'], row['dest'], weight=row['distance'])\n",
    "        \n",
    "    print('Calculating the minimum spanning tree of the graph...')\n",
    "    T = nx.minimum_spanning_tree(G)\n",
    "        \n",
    "    edges = T.edges(data=True)\n",
    "    weights = [x[2]['weight'] for x in edges]\n",
    "    total_dist = sum(weights)*1000\n",
    "        \n",
    "    print('Number of nodes (buildings) in the graph: ', T.number_of_nodes())\n",
    "    print('Number of edges in the minimum spanning tree: ', T.number_of_edges())\n",
    "    print('Total distance of minimum spanning tree (in m): ', total_dist)\n",
    "    \n",
    "    \n",
    "    #The section below simply allows to have a rough estimate of the number of clusters and cabling distances\n",
    "    #depending on their size:\n",
    "    if 0 < no_points <= 100:\n",
    "        clusters_under_100 = clusters_under_100 + 1\n",
    "        total_distance_under100 = total_distance_under100 + total_dist\n",
    "    elif 100 < no_points <= 300:\n",
    "        clusters_100_300 = clusters_100_300 + 1\n",
    "        total_distance_100_300 = total_distance_100_300 + total_dist\n",
    "    elif 300 < no_points <= 500:\n",
    "        clusters_300_500 = clusters_300_500 + 1\n",
    "        total_distance_300_500 = total_distance_300_500 + total_dist\n",
    "    elif 500 < no_points:\n",
    "        clusters_1000 = clusters_1000 + 1\n",
    "        total_distance_1000 = total_distance_1000 + total_dist\n",
    "    \n",
    "    #Create a geopandas dataframe and save as .shp\n",
    "\n",
    "    # create an array of LineString from T\n",
    "    lines = [LineString([(newcoords[int(edge[0]),0],newcoords[int(edge[0]),1]),(newcoords[int(edge[1]),0],newcoords[int(edge[1]),1])]) for edge in edges]\n",
    "\n",
    "    d = {'geometry':lines}\n",
    "    mstDF = gp.GeoDataFrame(d, crs=\"EPSG:4326\")\n",
    "    mstDF.to_file(\"MST\"+str(klass)+\".shp\")\n",
    "\n",
    "        \n",
    "    print('Plotting results:')\n",
    "        \n",
    "    # Plot Minimum Spanning Tree made from Delaunay Triangulation\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    nx.draw_networkx(T, pos=locations, with_labels=False, node_size=15)\n",
    "    plt.title('Minimum Spanning Tree of Delaunay Graph \\n (Edge Weight = Haversine Distance)')\n",
    "    plt.xlabel('Longitude ($^\\circ$)')\n",
    "    plt.ylabel('Latitude ($^\\circ$)')\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([min(newcoords[:, 0]) - 0.001, max(newcoords[:, 0]) + 0.001])\n",
    "    axes.set_ylim([min(newcoords[:, 1]) - 0.001, max(newcoords[:, 1]) + 0.001])\n",
    "        \n",
    "    # Plot relative frequency of edge distances in minimum spanning tree\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(weights, bins=200)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel('Number of edges of this distance')\n",
    "    plt.xlabel('Distance (km)')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print (f'under 100:{clusters_under_100} clusters and {total_distance_under100} m cabling')\n",
    "print (f'100-300:{clusters_100_300} clusters and {total_distance_100_300} m cabling')\n",
    "print (f'300-500:{clusters_300_500} clusters and {total_distance_300_500} m cabling')\n",
    "print (f'1000:{clusters_1000} clusters and {total_distance_1000} m cabling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a86359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last step is to interconnect clusters together when desirable; below is the centroid-cluster method but \n",
    "#the k-nearest neighbor algorithm would be more accurate and should be implemented by a technical expert.\n",
    "#Moreover, cabling along roads should be prioritized. This piece of code is simply to give a brief estimate\n",
    "#of cabling distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get centroid of each cluster\n",
    "all_centroids = []\n",
    "for klass in range(0,298):\n",
    "    newcoords2 = coords[labels == klass]\n",
    "    no_points = len(newcoords2)\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    for k in range(0, no_points):\n",
    "        sum_x = sum_x + newcoords2[k, 0]\n",
    "        sum_y = sum_y + newcoords2[k, 1]\n",
    "    centroid_x = sum_x / no_points\n",
    "    centroid_y = sum_y / no_points\n",
    "    all_centroids.append([centroid_x, centroid_y])\n",
    "\n",
    "all_centroids = np.asarray(all_centroids)\n",
    "\n",
    "print(all_centroids)\n",
    "\n",
    "#Plot the cluster centroids\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.scatter(x=all_centroids[:,0], y=all_centroids[:,1],color='r', s=1, alpha=0.8)\n",
    "plt.ylabel('Latitude')\n",
    "plt.xlabel('Longitude')   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Delauney triangulation of cluster centroid coordinates\n",
    "tri = Delaunay(all_centroids)\n",
    "indices = tri.vertex_neighbor_vertices[0]\n",
    "indptr = tri.vertex_neighbor_vertices[1]\n",
    "\n",
    "# Instantiate dictionary to hold neighbors of each point & data-frame to hold distances between neighbours\n",
    "neighbors = {}\n",
    "locations = {}\n",
    "distances = pd.DataFrame(columns=[\"source\", \"dest\", \"distance\"])\n",
    "\n",
    "# Get dictionary of neighbors of all points and a dictionary of locations of all points\n",
    "for k in range(0, len(all_centroids)):\n",
    "    neighbors[k] = indptr[indices[k]:indices[k+1]]\n",
    "    locations[k] = all_centroids[k][0], all_centroids[k][1]\n",
    "\n",
    "# Get distances between all Delaunay neighbors\n",
    "for key, values in neighbors.items():\n",
    "    for value in values:\n",
    "        coord_1 = all_centroids[key]\n",
    "        coord_2 = all_centroids[value]\n",
    "        dist = haversine_dist_from_coords(coord_1[1], coord_1[0], coord_2[1], coord_2[0])\n",
    "        distances = distances.append({\"source\": key, \"dest\": value, \"distance\": dist}, ignore_index=True)\n",
    "\n",
    "# Plot Delaunay triangulation\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.title('Delaunay Triangulation of Cluster Centroids')\n",
    "plt.triplot(all_centroids[:, 0], all_centroids[:, 1], tri.simplices)\n",
    "plt.xlabel('Longitude ($^\\circ$)')\n",
    "plt.ylabel('Latitude ($^\\circ$)')\n",
    "plt.plot(all_centroids[:, 0], all_centroids[:, 1], 'o')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([min(all_centroids[:, 0]) - 0.001, max(all_centroids[:, 0]) + 0.001])\n",
    "axes.set_ylim([min(all_centroids[:, 1]) - 0.001, max(all_centroids[:, 1]) + 0.001])\n",
    "\n",
    "print('Creating a graph from this information (edge weight = distance)...')\n",
    "G = nx.Graph()\n",
    "for index, row in distances.iterrows():\n",
    "    G.add_edge(row['source'], row['dest'], weight=row['distance'])\n",
    "\n",
    "print('Calculating the minimum spanning tree of the graph...')\n",
    "T = nx.minimum_spanning_tree(G)\n",
    "\n",
    "edges = T.edges(data=True)\n",
    "weights = [x[2]['weight'] for x in edges]\n",
    "total_dist = sum(weights)\n",
    "\n",
    "print('Number of nodes (buildings) in the graph: ', T.number_of_nodes())\n",
    "print('Number of edges in the minimum spanning tree: ', T.number_of_edges())\n",
    "print('Total distance of minimum spanning tree (in km): ', total_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plotting results:')\n",
    "\n",
    "# Plot Minimum Spanning Tree made from Delaunay Triangulation\n",
    "plt.figure(figsize=(7, 7))\n",
    "nx.draw_networkx(T, pos=locations, with_labels=False, node_size=15)\n",
    "plt.title('Minimum Spanning Tree of Delaunay Graph \\n (Edge Weight = Haversine Distance)')\n",
    "plt.xlabel('Longitude ($^\\circ$)')\n",
    "plt.ylabel('Latitude ($^\\circ$)')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([min(all_centroids[:, 0]) - 0.01, max(all_centroids[:, 0]) + 0.01])\n",
    "axes.set_ylim([min(all_centroids[:, 1]) - 0.01, max(all_centroids[:, 1]) + 0.01])\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ffbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geopandas dataframe and save as .shp\n",
    "\n",
    "# create an array of LineString from T\n",
    "lines = [LineString([(all_centroids[int(edge[0]),0],all_centroids[int(edge[0]),1]),(all_centroids[int(edge[1]),0],all_centroids[int(edge[1]),1])]) for edge in edges]\n",
    "\n",
    "d = {'geometry':lines}\n",
    "mstDF = gp.GeoDataFrame(d, crs=\"EPSG:4326\")\n",
    "mstDF.to_file(\"intraclusterMST.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dff3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
